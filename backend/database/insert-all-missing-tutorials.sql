-- ========================================
-- INS√âRER TOUS LES TUTORIELS MANQUANTS
-- Cloud (4) + Docker (4) + autres si n√©cessaire
-- ========================================
-- IMPORTANT: Remplacez '3cd1dbe8-35c8-4eb3-8e91-6d1e899028c3' par votre user_id

-- ========================================
-- CAT√âGORIE : CLOUD (4 tutoriels)
-- ========================================

-- CLOUD 1: AWS Architecture 3-Tiers
INSERT INTO blog_posts (
    user_id, title, slug, content, excerpt, cover_image, category, tags,
    status, published_at, views, read_time, seo_title, seo_description, seo_keywords
) VALUES (
    '3cd1dbe8-35c8-4eb3-8e91-6d1e899028c3',
    'AWS : D√©ployer une Architecture 3-Tiers Scalable',
    'aws-architecture-3-tiers',
    $BODY$# AWS : Architecture 3-Tiers Production-Ready

## üéØ Use Case : Application Web Scalable

Startup qui passe de 1000 √† 1 million d'utilisateurs. Architecture : Load Balancer ‚Üí Serveurs Web (Auto-Scaling) ‚Üí Base de donn√©es (Multi-AZ).

## Architecture

```
Internet ‚Üí CloudFront (CDN) ‚Üí ALB ‚Üí EC2 Auto-Scaling Group ‚Üí RDS Multi-AZ
```

## √âtape 1 : VPC et Subnets

```hcl
resource "aws_vpc" "main" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true

  tags = {
    Name = "production-vpc"
  }
}

resource "aws_subnet" "public" {
  count = 3

  vpc_id                  = aws_vpc.main.id
  cidr_block              = "10.0.${count.index + 1}.0/24"
  availability_zone       = data.aws_availability_zones.available.names[count.index]
  map_public_ip_on_launch = true

  tags = {
    Name = "public-subnet-${count.index + 1}"
  }
}

resource "aws_subnet" "private" {
  count = 3

  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.${count.index + 11}.0/24"
  availability_zone = data.aws_availability_zones.available.names[count.index]

  tags = {
    Name = "private-subnet-${count.index + 1}"
  }
}
```

## √âtape 2 : Application Load Balancer

```hcl
resource "aws_lb" "main" {
  name               = "app-alb"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.alb.id]
  subnets            = aws_subnet.public[*].id

  enable_deletion_protection = true

  tags = {
    Name = "production-alb"
  }
}

resource "aws_lb_target_group" "app" {
  name     = "app-tg"
  port     = 80
  protocol = "HTTP"
  vpc_id   = aws_vpc.main.id

  health_check {
    path                = "/health"
    healthy_threshold   = 2
    unhealthy_threshold = 10
  }
}
```

## √âtape 3 : Auto-Scaling Group

```hcl
resource "aws_launch_template" "app" {
  name_prefix   = "app-lt-"
  image_id      = data.aws_ami.amazon_linux_2.id
  instance_type = "t3.micro"

  user_data = base64encode(<<-EOF
    #!/bin/bash
    yum update -y
    yum install -y docker
    systemctl start docker
    docker run -d -p 80:8080 myapp:latest
  EOF
  )

  network_interfaces {
    associate_public_ip_address = false
    security_groups             = [aws_security_group.app.id]
  }
}

resource "aws_autoscaling_group" "app" {
  desired_capacity    = 2
  max_size            = 10
  min_size            = 2
  target_group_arns   = [aws_lb_target_group.app.arn]
  vpc_zone_identifier = aws_subnet.private[*].id

  launch_template {
    id      = aws_launch_template.app.id
    version = "$Latest"
  }

  tag {
    key                 = "Name"
    value               = "app-server"
    propagate_at_launch = true
  }
}
```

## √âtape 4 : RDS Multi-AZ

```hcl
resource "aws_db_instance" "main" {
  identifier             = "production-db"
  engine                 = "postgres"
  engine_version         = "15.3"
  instance_class         = "db.t3.micro"
  allocated_storage      = 20
  storage_encrypted      = true

  db_name  = "myapp"
  username = "admin"
  password = var.db_password

  multi_az               = true
  db_subnet_group_name   = aws_db_subnet_group.main.name
  vpc_security_group_ids = [aws_security_group.db.id]

  backup_retention_period = 7
  backup_window          = "03:00-04:00"
  maintenance_window     = "mon:04:00-mon:05:00"

  skip_final_snapshot = false
  final_snapshot_identifier = "production-db-final-snapshot"
}
```

## ROI

- **Haute Disponibilit√©** : 99.99% uptime
- **Scalabilit√©** : 2 ‚Üí 100 instances automatiquement
- **Co√ªts** : Pay-as-you-go, -40% vs serveurs d√©di√©s$BODY$,
    'D√©ployez une architecture AWS 3-tiers scalable avec Terraform. VPC, ALB, Auto-Scaling, RDS Multi-AZ. Production-ready avec haute disponibilit√©.',
    '/images/tutorials/cloud-aws.svg',
    'Cloud',
    ARRAY['AWS', 'Cloud', 'Terraform', '3-Tiers', 'Architecture', 'Scalability'],
    'published',
    NOW() - INTERVAL '25 days',
    0,
    23,
    'AWS Architecture 3-Tiers : Scalable et Haute Disponibilit√©',
    'Architecture AWS 3-tiers avec Terraform. VPC, ALB, Auto-Scaling, RDS Multi-AZ. Production-ready 99.99% uptime.',
    ARRAY['aws', 'cloud', 'terraform', '3-tiers', 'architecture', 'scalability']
);

-- CLOUD 2: Azure DevOps + AKS
INSERT INTO blog_posts (
    user_id, title, slug, content, excerpt, cover_image, category, tags,
    status, published_at, views, read_time, seo_title, seo_description, seo_keywords
) VALUES (
    '3cd1dbe8-35c8-4eb3-8e91-6d1e899028c3',
    'Azure : Pipeline DevOps Complet avec AKS et ACR',
    'azure-devops-aks-pipeline',
    $BODY$# Azure DevOps + AKS : CI/CD Cloud-Native

## üéØ Use Case : Microservices sur Azure Kubernetes

Entreprise qui migre 20 microservices vers Azure. Pipeline complet : Build ‚Üí Test ‚Üí Push ACR ‚Üí Deploy AKS.

## Architecture

```
Azure Repos ‚Üí Azure Pipelines ‚Üí Azure Container Registry ‚Üí Azure Kubernetes Service
```

## √âtape 1 : Cr√©er AKS Cluster

```bash
# Cr√©er Resource Group
az group create --name myapp-rg --location westeurope

# Cr√©er AKS
az aks create \
  --resource-group myapp-rg \
  --name myapp-aks \
  --node-count 3 \
  --enable-addons monitoring \
  --generate-ssh-keys

# Connecter kubectl
az aks get-credentials --resource-group myapp-rg --name myapp-aks
```

## √âtape 2 : Azure Pipeline YAML

```yaml
trigger:
  branches:
    include:
      - main

variables:
  dockerRegistryServiceConnection: 'myacr-connection'
  imageRepository: 'myapp'
  containerRegistry: 'myacr.azurecr.io'
  dockerfilePath: '$(Build.SourcesDirectory)/Dockerfile'
  tag: '$(Build.BuildId)'

stages:
- stage: Build
  displayName: Build and Push
  jobs:
  - job: Build
    displayName: Build
    pool:
      vmImage: 'ubuntu-latest'
    steps:
    - task: Docker@2
      displayName: Build and push image
      inputs:
        command: buildAndPush
        repository: $(imageRepository)
        dockerfile: $(dockerfilePath)
        containerRegistry: $(dockerRegistryServiceConnection)
        tags: |
          $(tag)
          latest

- stage: Deploy
  displayName: Deploy to AKS
  dependsOn: Build
  jobs:
  - deployment: Deploy
    displayName: Deploy
    pool:
      vmImage: 'ubuntu-latest'
    environment: 'production'
    strategy:
      runOnce:
        deploy:
          steps:
          - task: KubernetesManifest@0
            displayName: Deploy to Kubernetes
            inputs:
              action: 'deploy'
              kubernetesServiceConnection: 'aks-connection'
              namespace: 'production'
              manifests: |
                $(Pipeline.Workspace)/manifests/deployment.yml
                $(Pipeline.Workspace)/manifests/service.yml
              containers: |
                $(containerRegistry)/$(imageRepository):$(tag)
```

## ROI

- **D√©ploiements** : 30 min ‚Üí 5 min
- **Rollback** : 1 commande
- **Co√ªts** : Pay-per-use, r√©duction 35%$BODY$,
    'Pipeline Azure DevOps complet avec AKS et ACR. Build, test, push, deploy automatis√©s. Microservices cloud-native sur Kubernetes manag√©.',
    '/images/tutorials/cloud-azure.svg',
    'Cloud',
    ARRAY['Azure', 'Cloud', 'AKS', 'DevOps', 'Kubernetes', 'CI/CD'],
    'published',
    NOW() - INTERVAL '30 days',
    0,
    25,
    'Azure DevOps + AKS : Pipeline CI/CD Cloud-Native Complet',
    'Pipeline Azure DevOps avec AKS et ACR. Build, test, deploy microservices. Kubernetes manag√© cloud-native.',
    ARRAY['azure', 'cloud', 'aks', 'devops', 'kubernetes', 'cicd']
);

-- CLOUD 3: GCP Cloud Run
INSERT INTO blog_posts (
    user_id, title, slug, content, excerpt, cover_image, category, tags,
    status, published_at, views, read_time, seo_title, seo_description, seo_keywords
) VALUES (
    '3cd1dbe8-35c8-4eb3-8e91-6d1e899028c3',
    'GCP Cloud Run : Serverless Containers Auto-Scalant',
    'gcp-cloud-run-serverless',
    $BODY$# GCP Cloud Run : Serverless Container Platform

## üéØ Use Case : API Serverless qui Scale √† 0

API REST avec trafic variable. 0 requ√™tes la nuit ‚Üí 10K requ√™tes/sec en journ√©e. Cloud Run scale automatiquement et co√ªte 0‚Ç¨ quand inutilis√©.

## Architecture

```
Client ‚Üí Cloud Load Balancing ‚Üí Cloud Run (Auto-Scale 0‚Üí1000) ‚Üí Cloud SQL
```

## D√©ploiement Simple

```bash
# Build et deploy en 1 commande
gcloud run deploy myapi \
  --source . \
  --platform managed \
  --region europe-west1 \
  --allow-unauthenticated \
  --min-instances 0 \
  --max-instances 100 \
  --cpu 1 \
  --memory 512Mi \
  --timeout 60s
```

## Configuration avanc√©e

```yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: myapi
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/minScale: "0"
        autoscaling.knative.dev/maxScale: "100"
        autoscaling.knative.dev/target: "80"
    spec:
      containers:
      - image: gcr.io/myproject/myapi:latest
        ports:
        - containerPort: 8080
        resources:
          limits:
            cpu: "1000m"
            memory: "512Mi"
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
```

## ROI

- **Co√ªts** : 0‚Ç¨ quand inutilis√©
- **Scaling** : 0 √† 1000 instances en secondes
- **Maintenance** : 0 (manag√©)$BODY$,
    'D√©ployez des containers serverless avec GCP Cloud Run. Auto-scaling de 0 √† 1000 instances. Pay-per-use, co√ªts optimis√©s. Production-ready.',
    '/images/tutorials/cloud-gcp.svg',
    'Cloud',
    ARRAY['GCP', 'Cloud', 'Serverless', 'Cloud Run', 'Containers', 'Auto-Scaling'],
    'published',
    NOW() - INTERVAL '35 days',
    0,
    20,
    'GCP Cloud Run : Serverless Containers Auto-Scalant',
    'Cloud Run serverless pour containers. Scale de 0 √† 1000 instances. Pay-per-use, co√ªts optimis√©s.',
    ARRAY['gcp', 'cloud', 'serverless', 'cloud run', 'containers', 'autoscaling']
);

-- CLOUD 4: Multi-Cloud Terraform
INSERT INTO blog_posts (
    user_id, title, slug, content, excerpt, cover_image, category, tags,
    status, published_at, views, read_time, seo_title, seo_description, seo_keywords
) VALUES (
    '3cd1dbe8-35c8-4eb3-8e91-6d1e899028c3',
    'Multi-Cloud : D√©ployer sur AWS, Azure et GCP avec Terraform',
    'multi-cloud-terraform-aws-azure-gcp',
    $BODY$# Multi-Cloud avec Terraform

## üéØ Use Case : √âviter le Vendor Lock-In

Entreprise qui veut r√©partir workloads sur 3 clouds : AWS (compute), Azure (DB), GCP (ML). Terraform unifie tout.

## Architecture

```
Terraform ‚Üí AWS (EC2) + Azure (SQL DB) + GCP (Vertex AI)
```

## Configuration Multi-Provider

```hcl
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    azurerm = {
      source  = "hashicorp/azurerm"
      version = "~> 3.0"
    }
    google = {
      source  = "hashicorp/google"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = "eu-west-1"
}

provider "azurerm" {
  features {}
}

provider "google" {
  project = "my-project"
  region  = "europe-west1"
}
```

## D√©ploiement Multi-Cloud

```hcl
# AWS : Compute
resource "aws_instance" "app" {
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t3.micro"
}

# Azure : Database
resource "azurerm_postgresql_server" "db" {
  name                = "myapp-db"
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name
}

# GCP : Machine Learning
resource "google_vertex_ai_endpoint" "ml" {
  display_name = "mymodel-endpoint"
  location     = "europe-west1"
}
```

## ROI

- **Flexibilit√©** : Meilleur service de chaque cloud
- **R√©silience** : Pas de single point of failure
- **Co√ªts** : Optimisation par workload$BODY$,
    'Infrastructure multi-cloud avec Terraform. AWS, Azure, GCP en 1 codebase. √âvitez le vendor lock-in. R√©silience et optimisation des co√ªts.',
    '/images/tutorials/cloud-multicloud.svg',
    'Cloud',
    ARRAY['Multi-Cloud', 'Terraform', 'AWS', 'Azure', 'GCP', 'IaC'],
    'published',
    NOW() - INTERVAL '38 days',
    0,
    22,
    'Multi-Cloud Terraform : AWS + Azure + GCP Unifi√©',
    'Infrastructure multi-cloud avec Terraform. AWS, Azure, GCP. Vendor lock-in √©vit√©, r√©silience maximale.',
    ARRAY['multi-cloud', 'terraform', 'aws', 'azure', 'gcp', 'iac']
);

-- ========================================
-- CAT√âGORIE : DOCKER (4 tutoriels - optionnel si Docker n'est pas dans les cat√©gories valides)
-- Si vous avez une erreur de contrainte, commentez cette section
-- ========================================

-- Note: Si 'Docker' n'est pas une cat√©gorie valide, ces tutoriels peuvent √™tre mis en 'DevOps' √† la place
-- Changez simplement 'Docker' par 'DevOps' dans les 4 INSERT ci-dessous

-- DOCKER 1: Multi-Stage Builds
INSERT INTO blog_posts (
    user_id, title, slug, content, excerpt, cover_image, category, tags,
    status, published_at, views, read_time, seo_title, seo_description, seo_keywords
) VALUES (
    '3cd1dbe8-35c8-4eb3-8e91-6d1e899028c3',
    'Docker Multi-Stage Builds : R√©duire vos Images de 1GB √† 50MB',
    'docker-multi-stage-builds-optimization',
    $BODY$# Docker Multi-Stage Builds

## üéØ Use Case : Image Node.js de 1.2GB ‚Üí 85MB

Application Node.js. Image initiale : 1.2GB. Apr√®s multi-stage : 85MB. Temps de d√©ploiement : -90%.

## Avant : Image Monolithique (1.2GB)

```dockerfile
FROM node:20
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build
CMD ["node", "dist/index.js"]
```

## Apr√®s : Multi-Stage (85MB)

```dockerfile
# Stage 1: Build
FROM node:20-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
RUN npm run build

# Stage 2: Production
FROM node:20-alpine
WORKDIR /app
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/node_modules ./node_modules
USER node
CMD ["node", "dist/index.js"]
```

## ROI

- Taille : 1.2GB ‚Üí 85MB (-93%)
- Push DockerHub : 5 min ‚Üí 15 sec
- D√©ploiement K8s : 2 min ‚Üí 10 sec$BODY$,
    'Optimisez vos images Docker avec multi-stage builds. R√©duisez de 1GB √† 50MB. D√©ploiements 10x plus rapides. Production-ready.',
    '/images/tutorials/docker-multistage.svg',
    'DevOps',
    ARRAY['Docker', 'Multi-Stage', 'Optimization', 'DevOps', 'Performance'],
    'published',
    NOW() - INTERVAL '48 days',
    0,
    18,
    'Docker Multi-Stage : R√©duire Images de 1GB √† 50MB',
    'Multi-stage builds Docker. Images 93% plus petites. D√©ploiements ultra-rapides. Distroless images.',
    ARRAY['docker', 'multi-stage', 'optimization', 'performance']
);

-- DOCKER 2: Docker Compose
INSERT INTO blog_posts (
    user_id, title, slug, content, excerpt, cover_image, category, tags,
    status, published_at, views, read_time, seo_title, seo_description, seo_keywords
) VALUES (
    '3cd1dbe8-35c8-4eb3-8e91-6d1e899028c3',
    'Docker Compose : Stack Microservices Compl√®te en Local',
    'docker-compose-microservices-local',
    $BODY$# Docker Compose : Orchestration Locale

## üéØ Use Case : 10 Services en 1 Commande

Environnement local : API, DB, Redis, RabbitMQ, frontend. `docker compose up` = tout d√©marre en 30 secondes.

## Docker Compose complet

```yaml
version: '3.8'

services:
  api:
    build: ./api
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/myapp
      - REDIS_URL=redis://redis:6379
    depends_on:
      - db
      - redis

  db:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: myapp
      POSTGRES_PASSWORD: password
    volumes:
      - db-data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

volumes:
  db-data:
```

## ROI

- Onboarding : 5 min vs 2 jours
- Environnement identique pour toute l'√©quipe$BODY$,
    'Orchestrez vos microservices localement avec Docker Compose. Stack compl√®te en 1 commande. Onboarding devs en 5 minutes.',
    '/images/tutorials/docker-compose.svg',
    'DevOps',
    ARRAY['Docker', 'Docker Compose', 'Microservices', 'Development'],
    'published',
    NOW() - INTERVAL '50 days',
    0,
    16,
    'Docker Compose : Stack Microservices Locale Compl√®te',
    'Docker Compose pour d√©veloppement local. Multi-conteneurs, healthchecks. Stack en 1 commande.',
    ARRAY['docker', 'docker compose', 'microservices', 'development']
);

-- DOCKER 3: Security
INSERT INTO blog_posts (
    user_id, title, slug, content, excerpt, cover_image, category, tags,
    status, published_at, views, read_time, seo_title, seo_description, seo_keywords
) VALUES (
    '3cd1dbe8-35c8-4eb3-8e91-6d1e899028c3',
    'S√©curit√© Docker : Hardening et Scan de Vuln√©rabilit√©s',
    'docker-security-hardening-best-practices',
    $BODY$# Docker Security Best Practices

## üéØ Use Case : Passer un Audit PCI-DSS

Application bancaire. Exigences : conteneurs non-root, images scann√©es, secrets chiffr√©s.

## Dockerfile S√©curis√©

```dockerfile
FROM node:20-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production

FROM gcr.io/distroless/nodejs20-debian11
WORKDIR /app
COPY --from=builder /app/node_modules ./node_modules
COPY --from=builder /app/dist ./dist
USER nonroot:nonroot
CMD ["dist/index.js"]
```

## Scan avec Trivy

```bash
trivy image myapp:latest
```

## ROI

- Vuln√©rabilit√©s : D√©tect√©es avant production
- Audit : Conformit√© automatique$BODY$,
    'S√©curisez vos conteneurs Docker. Hardening, scan vuln√©rabilit√©s, distroless images. Conformit√© audit PCI-DSS.',
    '/images/tutorials/docker-security.svg',
    'DevOps',
    ARRAY['Docker', 'Security', 'DevSecOps', 'Hardening'],
    'published',
    NOW() - INTERVAL '52 days',
    0,
    19,
    'Docker Security : Hardening et Scan Vuln√©rabilit√©s',
    'S√©curisez Docker. Scan vuln√©rabilit√©s, hardening, distroless. Conformit√© audit.',
    ARRAY['docker', 'security', 'devsecops', 'hardening']
);

-- DOCKER 4: Registry
INSERT INTO blog_posts (
    user_id, title, slug, content, excerpt, cover_image, category, tags,
    status, published_at, views, read_time, seo_title, seo_description, seo_keywords
) VALUES (
    '3cd1dbe8-35c8-4eb3-8e91-6d1e899028c3',
    'Harbor : Registry Docker Priv√© avec Scan Automatique',
    'docker-harbor-private-registry-security',
    $BODY$# Harbor : Private Docker Registry

## üéØ Use Case : Registry Priv√© Entreprise

50 images Docker priv√©es. Harbor = registry + scan vuln√©rabilit√©s + replication.

## Installation Harbor

```bash
wget https://github.com/goharbor/harbor/releases/download/v2.9.0/harbor-online-installer-v2.9.0.tgz
tar xzvf harbor-online-installer-v2.9.0.tgz
cd harbor
./install.sh
```

## Scan Automatique

Harbor scan automatiquement avec Trivy :
- CVE d√©tect√©es
- Secrets hardcod√©s
- Mauvaises configurations

## ROI

- Images scann√©es automatiquement
- Blocage images vuln√©rables
- Conformit√© s√©curit√©$BODY$,
    'Registry Docker priv√© avec Harbor. Scan automatique vuln√©rabilit√©s avec Trivy. Policies de s√©curit√©. Entreprise-ready.',
    '/images/tutorials/docker-harbor.svg',
    'DevOps',
    ARRAY['Docker', 'Harbor', 'Registry', 'Security', 'Trivy'],
    'published',
    NOW() - INTERVAL '55 days',
    0,
    21,
    'Harbor Registry Docker : Scan Vuln√©rabilit√©s Automatique',
    'Registry Docker priv√© Harbor. Scan Trivy, policies s√©curit√©. Conformit√© entreprise.',
    ARRAY['docker', 'harbor', 'registry', 'security', 'trivy']
);
