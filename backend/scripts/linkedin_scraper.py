#!/usr/bin/env python3
"""
Script de scraping LinkedIn pour Portfolio

‚ö†Ô∏è AVERTISSEMENT IMPORTANT ‚ö†Ô∏è
-------------------------------
Le scraping de LinkedIn peut violer les conditions d'utilisation de LinkedIn.
LinkedIn interdit explicitement le scraping automatis√© dans ses CGU.

ALTERNATIVES RECOMMAND√âES :
1. T√©l√©charger vos donn√©es via LinkedIn Data Export (GDPR)
2. Utiliser l'API officielle LinkedIn (n√©cessite OAuth)
3. Saisir manuellement vos donn√©es dans data.json

Ce script est fourni √† des fins √âDUCATIVES uniquement.
Utilisez-le UNIQUEMENT pour votre propre profil public.

M√âTHODE L√âGALE RECOMMAND√âE :
‚Üí Voir le fichier LINKEDIN_DATA_EXPORT.md
"""

import json
import sys
import argparse
from urllib.parse import urlparse

# V√©rifier les d√©pendances
try:
    import requests
    from bs4 import BeautifulSoup
except ImportError:
    print("‚ùå D√©pendances manquantes. Installez-les avec :")
    print("   pip install requests beautifulsoup4")
    sys.exit(1)


class LinkedInProfileExtractor:
    """
    Extracteur de profil LinkedIn public

    ‚ö†Ô∏è LIMITATIONS :
    - Fonctionne uniquement sur les profils publics
    - LinkedIn bloque souvent les requ√™tes automatis√©es
    - Les donn√©es peuvent √™tre incompl√®tes
    - Peut cesser de fonctionner √† tout moment
    """

    def __init__(self, profile_url):
        self.profile_url = profile_url
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept-Language': 'fr-FR,fr;q=0.9,en;q=0.8',
        }
        self.data = {}

    def extract(self):
        """
        Extrait les donn√©es du profil

        Note: Cette m√©thode est tr√®s limit√©e car LinkedIn
        charge la plupart du contenu via JavaScript.
        """
        print(f"üîç Tentative d'extraction depuis : {self.profile_url}")
        print("‚ö†Ô∏è  LinkedIn bloque g√©n√©ralement ce type de requ√™te...")

        try:
            response = requests.get(self.profile_url, headers=self.headers, timeout=10)

            if response.status_code == 999:
                print("\n‚ùå LinkedIn a bloqu√© la requ√™te (code 999)")
                print("üí° Solution : Utilisez la m√©thode GDPR Data Export (voir LINKEDIN_DATA_EXPORT.md)")
                return None

            if response.status_code != 200:
                print(f"\n‚ùå Erreur HTTP {response.status_code}")
                return None

            soup = BeautifulSoup(response.content, 'html.parser')

            # Tentative d'extraction (tr√®s limit√©e)
            self.data = {
                'profile': {
                    'name': self._extract_name(soup),
                    'title': self._extract_title(soup),
                    'location': self._extract_location(soup),
                    'linkedin': self.profile_url,
                    'about': ''
                }
            }

            print("\n‚úÖ Extraction partielle r√©ussie (donn√©es limit√©es)")
            print("üí° Pour des donn√©es compl√®tes, utilisez LinkedIn Data Export")

            return self.data

        except requests.RequestException as e:
            print(f"\n‚ùå Erreur de connexion : {e}")
            return None

    def _extract_name(self, soup):
        """Tente d'extraire le nom"""
        # LinkedIn change souvent ses s√©lecteurs
        selectors = [
            'h1.top-card-layout__title',
            'h1.text-heading-xlarge',
            '.pv-text-details__left-panel h1'
        ]

        for selector in selectors:
            element = soup.select_one(selector)
            if element:
                return element.get_text().strip()

        return "Nom non trouv√©"

    def _extract_title(self, soup):
        """Tente d'extraire le titre"""
        selectors = [
            'div.top-card-layout__headline',
            '.text-body-medium',
            '.pv-text-details__left-panel .text-body-medium'
        ]

        for selector in selectors:
            element = soup.select_one(selector)
            if element:
                return element.get_text().strip()

        return "Titre non trouv√©"

    def _extract_location(self, soup):
        """Tente d'extraire la localisation"""
        selectors = [
            'span.top-card__subline-item',
            '.pv-text-details__left-panel .text-body-small'
        ]

        for selector in selectors:
            element = soup.select_one(selector)
            if element:
                return element.get_text().strip()

        return "Localisation non trouv√©e"

    def save_to_json(self, output_file='linkedin_data.json'):
        """Sauvegarde les donn√©es extraites en JSON"""
        if not self.data:
            print("‚ùå Aucune donn√©e √† sauvegarder")
            return False

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.data, f, indent=2, ensure_ascii=False)

        print(f"\n‚úÖ Donn√©es sauvegard√©es dans : {output_file}")
        return True


def main():
    parser = argparse.ArgumentParser(
        description='Extraction de profil LinkedIn (√âDUCATIF UNIQUEMENT)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
‚ö†Ô∏è  AVERTISSEMENT ‚ö†Ô∏è
Ce script peut violer les CGU de LinkedIn.

M√âTHODES ALTERNATIVES RECOMMAND√âES :
1. LinkedIn Data Export (GDPR) - L√âGAL et COMPLET
   ‚Üí Voir LINKEDIN_DATA_EXPORT.md

2. API officielle LinkedIn
   ‚Üí N√©cessite OAuth et approbation

3. Saisie manuelle dans data.json

Exemple d'utilisation :
  python linkedin_scraper.py https://www.linkedin.com/in/alicesindayigaya
        """
    )

    parser.add_argument('profile_url', help='URL du profil LinkedIn')
    parser.add_argument('-o', '--output', default='linkedin_data.json',
                       help='Fichier de sortie JSON (d√©faut: linkedin_data.json)')

    args = parser.parse_args()

    # Validation de l'URL
    parsed = urlparse(args.profile_url)
    if 'linkedin.com' not in parsed.netloc:
        print("‚ùå URL invalide. Doit √™tre une URL LinkedIn.")
        sys.exit(1)

    print("\n" + "="*60)
    print("  SCRAPER LINKEDIN - √Ä DES FINS √âDUCATIVES UNIQUEMENT")
    print("="*60)
    print("\n‚ö†Ô∏è  Ce script a de fortes chances d'√©chouer.")
    print("üí° M√©thode recommand√©e : LinkedIn Data Export (GDPR)")
    print("   Voir le fichier LINKEDIN_DATA_EXPORT.md\n")

    input("Appuyez sur Entr√©e pour continuer (Ctrl+C pour annuler)...")

    # Extraction
    extractor = LinkedInProfileExtractor(args.profile_url)
    data = extractor.extract()

    if data:
        extractor.save_to_json(args.output)
        print("\nüìù Prochaines √©tapes :")
        print("   1. V√©rifiez les donn√©es dans", args.output)
        print("   2. Compl√©tez manuellement les informations manquantes")
        print("   3. Importez dans votre portfolio")
    else:
        print("\n‚ùå √âchec de l'extraction")
        print("\nüí° Utilisez plut√¥t LinkedIn Data Export :")
        print("   1. Allez sur LinkedIn > Param√®tres > Confidentialit√©")
        print("   2. 'Obtenir une copie de vos donn√©es'")
        print("   3. T√©l√©chargez l'archive")
        print("   4. Utilisez le script linkedin_import.py")


if __name__ == '__main__':
    main()
